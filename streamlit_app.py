# Streamlit UI for Korean Sentiment Analysis
# Loads the model directly â€” no separate API server needed

import streamlit as st
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# --- Page Config ---
st.set_page_config(
    page_title="Korean Sentiment Analyzer",
    page_icon="ðŸ‡°ðŸ‡·",
    layout="centered"
)

# --- Constants ---
# Read model name from config so it's not hardcoded
import yaml
from pathlib import Path

_config_path = Path(__file__).parent / "configs" / "model_config.yaml"
with open(_config_path) as _f:
    _config = yaml.safe_load(_f)
MODEL_NAME = _config["model_name"]

# --- Emotion Emoji Map ---
EMOTION_EMOJIS = {
    "ê¸°ì¨(í–‰ë³µí•œ)": "ðŸ˜Š",
    "ìŠ¬í””": "ðŸ˜¢",
    "ë¶„ë…¸": "ðŸ˜¡",
    "ë¶ˆì•ˆ": "ðŸ˜°",
    "ìƒì²˜(ë°°ì‹ ë‹¹í•œ)": "ðŸ’”",
    "ë‹¹í™©": "ðŸ˜³",
    "ê¸°ì¨": "ðŸ˜Š",
    "ë†€ëžŒ": "ðŸ˜²",
    "í˜ì˜¤": "ðŸ¤®",
    "ê³µí¬": "ðŸ˜±",
    "ì¤‘ë¦½": "ðŸ˜",
}


def get_emoji(label: str) -> str:
    """Get emoji for a given emotion label."""
    return EMOTION_EMOJIS.get(label, "ðŸ”®")


@st.cache_resource
def load_model():
    """Load model and tokenizer once, cached across reruns."""
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
    model.eval()
    return tokenizer, model


def analyze_sentiment(text: str) -> dict | None:
    """Run sentiment prediction directly on the model."""
    try:
        tokenizer, model = load_model()

        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=128,
        )

        with torch.no_grad():
            outputs = model(**inputs)

        logits = outputs.logits
        probabilities = F.softmax(logits, dim=-1)
        predicted_class_id = torch.argmax(probabilities, dim=-1).item()
        confidence = probabilities[0][predicted_class_id].item()

        if hasattr(model.config, "id2label"):
            label = model.config.id2label[predicted_class_id]
        else:
            label = str(predicted_class_id)

        return {"label": label, "confidence": round(confidence, 4)}
    except Exception as e:
        st.error(f"Model Error: {e}")
        return None


# --- UI ---
st.title("ðŸ‡°ðŸ‡· Korean Sentiment Analyzer")
st.markdown("Analyze the emotion in Korean text using AI (KcELECTRA model)")

# Load model on startup (shows spinner first time)
with st.spinner("Loading AI model... (first time only)"):
    load_model()
st.sidebar.success("âœ… Model loaded")

st.divider()

# --- Input Section ---
text_input = st.text_area(
    "Enter Korean text to analyze:",
    placeholder="ì˜ˆ: ì´ ì˜í™” ì •ë§ ìž¬ë¯¸ìžˆì–´ìš”!",
    height=120
)

# Example buttons
st.markdown("**Try an example:**")
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ðŸ˜Š Happy", use_container_width=True):
        text_input = "ì˜¤ëŠ˜ í•˜ë£¨ ë„ˆë¬´ í–‰ë³µí•´ìš”! ì¢‹ì€ ì¼ì´ ê°€ë“í–ˆì–´ìš”."
        st.session_state["text"] = text_input

with col2:
    if st.button("ðŸ˜¢ Sad", use_container_width=True):
        text_input = "ë„ˆë¬´ ìŠ¬í¼ì„œ ëˆˆë¬¼ì´ ë‚˜ìš”. ì™œ ì´ë ‡ê²Œ íž˜ë“¤ê¹Œ."
        st.session_state["text"] = text_input

with col3:
    if st.button("ðŸ˜¡ Angry", use_container_width=True):
        text_input = "ì •ë§ í™”ê°€ ë‚˜ìš”! ì´ê±´ ë„ˆë¬´ ë¶ˆê³µí‰í•´ìš”."
        st.session_state["text"] = text_input

# Use session state for example buttons
if "text" in st.session_state and not text_input:
    text_input = st.session_state["text"]

st.divider()

# --- Analyze Button ---
if st.button("ðŸ” Analyze Sentiment", type="primary", use_container_width=True):
    if not text_input or not text_input.strip():
        st.warning("Please enter some Korean text first!")
    else:
        with st.spinner("Analyzing..."):
            result = analyze_sentiment(text_input.strip())

        if result:
            label = result["label"]
            confidence = result["confidence"]
            emoji = get_emoji(label)

            # Results display
            st.markdown("### Results")

            result_col1, result_col2 = st.columns(2)

            with result_col1:
                st.metric(
                    label="Detected Emotion",
                    value=f"{emoji} {label}"
                )

            with result_col2:
                st.metric(
                    label="Confidence",
                    value=f"{confidence * 100:.1f}%"
                )

            # Confidence bar
            st.progress(confidence)

            # Interpretation
            if confidence >= 0.8:
                st.success(f"High confidence â€” the model is quite sure this is **{label}**")
            elif confidence >= 0.5:
                st.info(f"Moderate confidence â€” likely **{label}**, but could be mixed emotions")
            else:
                st.warning(f"Low confidence â€” the model is unsure. Best guess: **{label}**")

# --- Footer ---
st.divider()
st.caption("Powered by KcELECTRA Â· Built with Streamlit Â· Hosted on Streamlit Community Cloud")
